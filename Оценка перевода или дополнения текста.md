**BLEU (BiLingual Evaluation Understudy)** — метрика, изначально разработанная для оценки качества машинного перевода. Она основана на подсчёте совпадений n-грамм (последовательностей из n слов) между сгенерированным текстом и одним или несколькими эталонными текстами. BLEU оценивает точность (precision) — долю n-грамм сгенерированного текста, которые встречаются в эталоне, и включает штраф за слишком короткие переводы (brevity penalty). Значения BLEU лежат от 0 до 1, где 1 — идеальное совпадение


**ROUGE (Recall-Oriented Understudy for Gisting Evaluation)** — семейство метрик, применяемое для оценки качества суммаризации и машинного перевода. В отличие от BLEU, ROUGE ориентируется в первую очередь на полноту (recall) — насколько полно сгенерированный текст охватывает информационное содержание эталона. Основные варианты:

- ROUGE-N: пересечение n-грамм (ROUGE-1 для слов, ROUGE-2 для биграмм).
    
- ROUGE-L: основана на длине наибольшей общей подпоследовательности (Longest Common Subsequence) между текстами, учитывает последовательность слов.
    
- ROUGE-S и ROUGE-SU: основаны на пропущенных биграммах (skip-bigrams).  
    ROUGE также может рассчитываться по точности, полноте и F1-мере, но для задач суммаризации важна именно полнота

**Perplexity (перплексия)** — метрика, применяемая для оценки языковых моделей. Она измеряет, насколько «удивлена» модель конкретной последовательностью текста, то есть насколько вероятна эта последовательность по модели. Более низкое значение perplexity означает, что модель хорошо предсказывает текст. Перплексия оценивает внутреннее качество модели и не требует эталонных текстов, в отличие от BLEU и ROUGE